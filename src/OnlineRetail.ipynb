{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEyH3jkdQDIY"
      },
      "source": [
        "# **Data Pre-Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8fPXuOcewJjX",
        "outputId": "6e1ee93e-fd14-4bf4-9309-7442c3a66e51"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# retail = \"Online Retail.xlsx\"\n",
        "retail = \"data/Online Retail.xlsx\" # use this for using local data within the repo.\n",
        "df = pd.read_excel(retail, sheet_name='Online Retail')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk3F2Vdawv3D",
        "outputId": "11d0bebd-6022-400e-ef02-6f1833e574b5"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "u7iE6Ohj2FY1",
        "outputId": "a27e088a-ae95-484e-d749-024a53c3cba5"
      },
      "outputs": [],
      "source": [
        "#Check for missing values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpZkwYyf2Z3V",
        "outputId": "12a38303-a362-4f29-cf39-84fdabf6ed08"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage of missing values\n",
        "null_percentage = df.isnull().sum() / len(df) * 100\n",
        "\n",
        "# Show missing values percentage\n",
        "print(null_percentage)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeNUtbV-30t8"
      },
      "outputs": [],
      "source": [
        "# Drop missing Customer IDs and Description\n",
        "df.dropna(subset=[\"CustomerID\", \"Description\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iYQwD5m4Bdt"
      },
      "outputs": [],
      "source": [
        "# Convert data types\n",
        "df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\n",
        "df[\"InvoiceNo\"] = df[\"InvoiceNo\"].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnp4IN_H6K1C"
      },
      "outputs": [],
      "source": [
        "# Remove negative or zero values in Quantity and UnitPrice\n",
        "df = df[(df[\"Quantity\"] > 0) & (df[\"UnitPrice\"] > 0)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fECjGuYCQX9U"
      },
      "source": [
        "# **Finding Optimal Numaber Of Clusters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo_Shx2rJwQe"
      },
      "source": [
        "\n",
        "The following block of code calculates three key metrics (Recency, Frequency, and Monetary) for customer segmentation in the Online Retail dataset.\n",
        "\n",
        "RFM analysis is used to group customers based on their purchase behavior. The three metrics represent:\n",
        "\n",
        "Recency: How recently a customer made a purchase.\n",
        "\n",
        "Frequency: How often a customer makes purchases.\n",
        "\n",
        "Monetary : How much a customer spends.\n",
        "\n",
        "Recency: Finds the latest purchase date for each customer.Calculates how many days have passed since their last purchase.\n",
        "\n",
        "Frequency:Counts the number of unique transactions each customer has made.\n",
        "\n",
        "Monetary: Computes the total spending per customer by multiplying Quantity * UnitPrice and summing the values.\n",
        "\n",
        "\n",
        "This would help us to identify loyal customers, high spenders, and inactive users.also, it can be used to group customers into categories. We can use the scores to create personalized marketing desicions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sCB75D0e4yj6",
        "outputId": "7ecda059-25fb-4a17-9c22-456978f7134b"
      },
      "outputs": [],
      "source": [
        "df = df.copy()\n",
        "\n",
        "# Compute the latest transaction date in the dataset\n",
        "latest_date = df[\"InvoiceDate\"].max()\n",
        "\n",
        "# Create \"TotalPrice\" column manually using .loc to avoid warning\n",
        "df.loc[:, \"TotalPrice\"] = df[\"Quantity\"] * df[\"UnitPrice\"]\n",
        "\n",
        "# Compute RFM metrics for each customer\n",
        "rfm = df.groupby(\"CustomerID\").agg(\n",
        "    Recency=(\"InvoiceDate\", lambda x: (latest_date - x.max()).days),  # Days since last purchase\n",
        "    Frequency=(\"InvoiceNo\", \"nunique\"),  # Count of unique transactions\n",
        "    Monetary=(\"TotalPrice\", \"sum\")  # Total spending amount\n",
        ").reset_index()  # Reset index\n",
        "\n",
        "# Display the first five rows\n",
        "rfm.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZXa5vwVXbXL"
      },
      "source": [
        "**Normalize The Data Using MinMaxScaler**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-wV0c3TPdYby",
        "outputId": "e8cea207-c93a-46f1-ef70-5b5f10134f42"
      },
      "outputs": [],
      "source": [
        "# Use MinMaxScaler for normalizing the original dataset to be used for algorithms except DBSCAN\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Apply log transformation (adding 1 to avoid log(0) issues)\n",
        "rfm_log = np.log1p(rfm[['Recency', 'Frequency', 'Monetary']])\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Apply MinMaxScaler to Recency, Frequency, and Monetary\n",
        "rfm_scaled = scaler.fit_transform(rfm_log[['Recency', 'Frequency', 'Monetary']])\n",
        "\n",
        "# Convert the result back into a DataFrame\n",
        "rfm_std = pd.DataFrame(rfm_scaled, columns=['Recency', 'Frequency', 'Monetary'])\n",
        "\n",
        "# Display the first few rows\n",
        "rfm_std.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "8VnOw1Y3ZZtx",
        "outputId": "c4c75db0-ced2-4427-ca80-5994a6c0940f"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr_matrix = rfm_std.corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Heatmap of RFM Features\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aer-L3MAXnDH"
      },
      "source": [
        "**Plot To Figure Out The Data Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "CalDcgx96QGI",
        "outputId": "e1f9db68-878a-4037-a358-5f0ff7920a45"
      },
      "outputs": [],
      "source": [
        "# style of the graph\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Subplots for each RFM feature\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Plot Recency distribution\n",
        "sns.histplot(rfm_std[\"Recency\"], bins=20, kde=True, ax=axes[0], color=\"blue\")\n",
        "axes[0].set_title(\"Recency Distribution\")\n",
        "axes[0].set_xlabel(\"Days Since Last Purchase\")\n",
        "\n",
        "# Plot Frequency distribution\n",
        "sns.histplot(rfm_std[\"Frequency\"], bins=20, kde=True, ax=axes[1], color=\"green\")\n",
        "axes[1].set_title(\"Frequency Distribution\")\n",
        "axes[1].set_xlabel(\"Number of Transactions\")\n",
        "\n",
        "# Plot Monetary distribution\n",
        "sns.histplot(rfm_std[\"Monetary\"], bins=20, kde=True, ax=axes[2], color=\"red\")\n",
        "axes[2].set_title(\"Monetary Distribution\")\n",
        "axes[2].set_xlabel(\"Total Spending\")\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "kcMVhMtHYye4",
        "outputId": "f77abf42-564b-4fcf-a113-8c21236fa297"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Set the style\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Create the 3D figure\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Scatter plot in 3D\n",
        "scatter= ax.scatter(rfm_std[\"Recency\"], rfm_std[\"Frequency\"], rfm_std[\"Monetary\"],\n",
        "           c=rfm_std[\"Monetary\"], cmap=\"coolwarm\", s=50, edgecolor='k')\n",
        "\n",
        "# Labels and title\n",
        "ax.set_xlabel(\"Recency\")\n",
        "ax.set_ylabel(\"Frequency\")\n",
        "ax.set_zlabel(\"Monetary\")\n",
        "ax.set_title(\"3D Visualization of RFM Segmentation\")\n",
        "\n",
        "# Add color bar to indicate classes\n",
        "cbar = plt.colorbar(scatter, ax=ax, shrink=0.6, pad=0.1)\n",
        "cbar.set_label(\"Class Labels\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDgmjL8v3cZR"
      },
      "source": [
        "**Implement PCA Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJiB39qR0Vxt"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "rfm_pca = pca.fit_transform(rfm_std)\n",
        "\n",
        "# Convert to DataFrame\n",
        "rfm_df = pd.DataFrame(rfm_pca, columns=[\"Recency\", \"Frequency\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfG7xm2uYbSv"
      },
      "source": [
        "**Using Elbow Method To find The Optimal Number Of Clusters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "gkt0077eNInR",
        "outputId": "2195d52f-ab99-47e1-9040-fa351f1dca98"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Initialize an empty list to store Within-Cluster Sum of Squares values\n",
        "wcss = []\n",
        "\n",
        "# Define the range of cluster numbers to test (from 2 to 10 clusters)\n",
        "K_range = range(2, 11)\n",
        "\n",
        "# Iterate over different values of k to find the optimal number of clusters\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)  # Initialize K-Means with k clusters\n",
        "    kmeans.fit(rfm_df)  # Fit the model to the standardized RFM data\n",
        "    wcss.append(kmeans.inertia_)  # Store the WCSS value for this k (lower is better)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Plot the WCSS values against the number of clusters\n",
        "plt.plot(K_range, wcss, marker='o', linestyle='--')\n",
        "\n",
        "# Label the axes\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"WCSS\")\n",
        "\n",
        "# Add a title to the plot\n",
        "plt.title(\"Elbow Method for Optimal k\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAo42oPjAa6S",
        "outputId": "3476b63c-0fdb-4287-c79d-1afbe49153f0"
      },
      "outputs": [],
      "source": [
        "!pip install kneed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t3fe-i9TpyL"
      },
      "source": [
        "**Optimal eps and min sample Selection for DBSCAN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "iwpGgdA1R9AN",
        "outputId": "d83c72e1-a0bc-4ff7-cbe8-45af6dd237b0"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "from kneed import KneeLocator\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "Features_rfm = rfm_df.iloc[:, 1:]\n",
        "features_std = scaler.fit_transform(Features_rfm)\n",
        "\n",
        "# Define a range of min_samples values to test\n",
        "min_samples_values = range(2, 20)\n",
        "\n",
        "# Store average k-distance for each min_samples\n",
        "eps_values = []\n",
        "\n",
        "for min_samples in min_samples_values:\n",
        "    # Compute k-distances\n",
        "    neighbors = NearestNeighbors(n_neighbors=min_samples)\n",
        "    neighbors.fit(features_std)\n",
        "    distances, indices = neighbors.kneighbors(features_std)\n",
        "\n",
        "    # Sort and take the k-th nearest distance\n",
        "    sorted_distances = np.sort(distances[:, -1])\n",
        "\n",
        "    # Find the knee (elbow point)\n",
        "    kneedle = KneeLocator(range(len(sorted_distances)), sorted_distances, curve=\"convex\", direction=\"increasing\")\n",
        "    optimal_eps = sorted_distances[kneedle.elbow]\n",
        "\n",
        "    eps_values.append(optimal_eps)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(min_samples_values, eps_values, marker=\"o\")\n",
        "plt.xlabel(\"min_samples\")\n",
        "plt.ylabel(\"Optimal eps\")\n",
        "plt.title(\"Optimal eps vs. min_samples for DBSCAN\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Print best min_samples value\n",
        "best_min_samples = min_samples_values[np.argmax(eps_values)]\n",
        "print(f\"Optimal min_samples for DBSCAN: {best_min_samples}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "Ttha_y_vS8DC",
        "outputId": "cc3f0e77-827d-4cac-eca8-c8a48a1f7a09"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set min_samples for DBSCAN\n",
        "min_samples = 4\n",
        "\n",
        "# Fit NearestNeighbors to find k-th nearest neighbor distances\n",
        "neighbors = NearestNeighbors(n_neighbors=min_samples)\n",
        "neighbors.fit(features_std)\n",
        "distances, indices = neighbors.kneighbors(features_std)\n",
        "\n",
        "# Sort the distances (use only the k-th nearest neighbor distance)\n",
        "distances = np.sort(distances[:, -1])\n",
        "\n",
        "# Find the optimal eps using the KneeLocator (Elbow Method)\n",
        "kneedle = KneeLocator(range(len(distances)), distances, curve=\"convex\", direction=\"increasing\")\n",
        "best_eps = distances[kneedle.elbow]  # Extract the best epsilon value\n",
        "\n",
        "# Print the best eps\n",
        "print(f\"Optimal epsilon (eps) for DBSCAN: {best_eps}\")\n",
        "\n",
        "# Plot the k-distance graph with the elbow point\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(distances, label=\"k-distance\")\n",
        "plt.axhline(y=best_eps, color='r', linestyle='--', label=f\"Best eps = {best_eps:.4f}\")\n",
        "plt.xlabel(\"Data Points Sorted by Distance\")\n",
        "plt.ylabel(f\"{min_samples}-th Nearest Neighbor Distance\")\n",
        "plt.title(\"K-Distance Graph for DBSCAN (Elbow Method)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnwfS4kKvx6g"
      },
      "source": [
        "**ptimal Number of Clusters for GMM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "bxojUfPnOrcA",
        "outputId": "3220cbd1-f016-4aeb-dd90-454a2c836510"
      },
      "outputs": [],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "bic_scores = []  # Initialize an empty list to store BIC scores\n",
        "\n",
        "for k in range(2, 11):  # Iterate over different numbers of clusters (from 2 to 10)\n",
        "    gmm = GaussianMixture(n_components=k, random_state=42)  # Initialize Gaussian Mixture Model with k clusters\n",
        "    gmm.fit(rfm_df)  # Fit the model to the RFM data\n",
        "    bic_scores.append(gmm.bic(rfm_df))  # Compute and store the Bayesian Information Criterion (BIC) score\n",
        "\n",
        "\n",
        "# Plot BIC scores\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(2, 11), bic_scores, marker='o', linestyle='--', color='r')\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"BIC Score\")\n",
        "plt.title(\"Optimal Number of Clusters for GMM (BIC)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUXqBwvVPt9I",
        "outputId": "fd211b43-b4a1-4924-84d8-94393565643b"
      },
      "outputs": [],
      "source": [
        "!pip install pyclustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4drdCQO6ggA"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import SpectralClustering, DBSCAN, Birch\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from pyclustering.cluster.clique import clique\n",
        "\n",
        "# Clustering Algorithms\n",
        "clustering_algorithms = {\n",
        "    \"Spectral Clustering\": SpectralClustering(n_clusters=3, affinity='rbf', random_state=42),\n",
        "    \"BIRCH\": Birch(n_clusters=3, threshold = 0.1),\n",
        "    \"DBSCAN\": DBSCAN(eps=0.0235 , min_samples=4),\n",
        "    \"Gaussian Mixture Model\": GaussianMixture(n_components=3, random_state=42),\n",
        "    \"CLIQUE\": clique\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc1jONe86xcL",
        "outputId": "b99de751-1f57-4827-c822-2dc660c1686d"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Compute Clustering Results\n",
        "cluster_results = {}\n",
        "validation_scores = {}\n",
        "\n",
        "# Fit each clustering model and store results\n",
        "for name, algorithm in clustering_algorithms.items():\n",
        "    if name == \"CLIQUE\":\n",
        "        # CLIQUE instantiation\n",
        "        clique_instance = clique(rfm_df.values.tolist(), 10, 2)\n",
        "        clique_instance.process()\n",
        "        clusters = clique_instance.get_clusters()\n",
        "\n",
        "        # Assign labels manually\n",
        "        labels = [-1] * len(rfm_df)  # Default label for noise points\n",
        "        for cluster_id, cluster in enumerate(clusters):\n",
        "            for idx in cluster:\n",
        "                labels[idx] = cluster_id  # Assign each point to a cluster\n",
        "\n",
        "    elif name == \"DBSCAN\":\n",
        "        # Use scaled features for DBSCAN\n",
        "        labels = algorithm.fit_predict(features_std)\n",
        "\n",
        "    else:\n",
        "        # Fit sklearn-compatible models with original features\n",
        "        labels = algorithm.fit_predict(rfm_df)\n",
        "\n",
        "    cluster_results[name] = labels  # Store cluster labels\n",
        "\n",
        "# Now iterate over cluster_results (which is no longer empty)\n",
        "for name, labels in cluster_results.items():\n",
        "    unique_labels = set(labels)\n",
        "    print(f\"{name} - Unique Clusters Found: {len(unique_labels)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "sYSmn-2JaVAk",
        "outputId": "1f8ee82e-db8c-451c-c875-18e566dd751e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "\n",
        "\n",
        "# Compute validation metrics for each clustering method\n",
        "for name, labels in cluster_results.items():\n",
        "    # Choose the correct dataset based on the clustering algorithm\n",
        "    if name == \"DBSCAN\":\n",
        "        data = features_std  # Use standardized features for DBSCAN\n",
        "    else:\n",
        "        data = rfm_df  # Use the RFM-normalized dataset for other clustering models\n",
        "\n",
        "    # Compute clustering validation metrics only if there is more than one cluster\n",
        "    if len(set(labels)) > 1:  # Silhouette Score requires at least 2 clusters\n",
        "        silhouette = silhouette_score(data, labels)\n",
        "    else:\n",
        "        silhouette = -1  # Assign -1 when only one cluster exists to avoid errors\n",
        "\n",
        "    # Compute Davies-Bouldin Index (lower is better)\n",
        "    db_index = davies_bouldin_score(data, labels)\n",
        "\n",
        "    # Compute Calinski-Harabasz Index (higher is better)\n",
        "    ch_index = calinski_harabasz_score(data, labels)\n",
        "\n",
        "    # Store validation scores in a dictionary\n",
        "    validation_scores[name] = {\n",
        "        \"Silhouette Score\": silhouette,\n",
        "        \"Davies-Bouldin Index\": db_index,\n",
        "        \"Calinski-Harabasz Index\": ch_index\n",
        "    }\n",
        "\n",
        "# Get the number of clustering methods used\n",
        "num_clusters = len(cluster_results)\n",
        "\n",
        "# Create subplots dynamically based on the number of clustering techniques\n",
        "fig, axes = plt.subplots(1, num_clusters, figsize=(5 * num_clusters, 5))\n",
        "fig.suptitle(\"Comparison of Clustering Techniques on RFM Data\", fontsize=14)\n",
        "\n",
        "# If only one clustering method exists, make sure axes is iterable\n",
        "if num_clusters == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "# Iterate through the clustering results and visualize the clusters\n",
        "for i, (name, labels) in enumerate(cluster_results.items()):\n",
        "    unique_labels = len(set(labels))  # Get number of unique clusters\n",
        "    palette = sns.color_palette(\"tab10\", n_colors=unique_labels)  # Define color palette\n",
        "\n",
        "    # Scatter plot for visualizing clustering on Recency vs Frequency\n",
        "    sns.scatterplot(\n",
        "        x=rfm_df[\"Recency\"],  # X-axis: Recency\n",
        "        y=rfm_df[\"Frequency\"],  # Y-axis: Frequency\n",
        "        hue=labels,  # Color clusters by labels\n",
        "        palette=palette,  # Use color palette based on unique labels\n",
        "        alpha=0.7,  # Set transparency for better visibility\n",
        "        s=8,  # Set point size\n",
        "        ax=axes[i]  # Assign plot to the respective subplot\n",
        "    )\n",
        "\n",
        "    # Set plot title and axis labels\n",
        "    axes[i].set_title(f\"{name}\")\n",
        "    axes[i].set_xlabel(\"Recency\")\n",
        "    axes[i].set_ylabel(\"Frequency\")\n",
        "\n",
        "    # Remove legends from each subplot to avoid redundancy\n",
        "    axes[i].legend([], frameon=False)\n",
        "\n",
        "# Adjust layout to prevent overlapping labels\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plots\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6MeYsqkvfYfK",
        "outputId": "fc92bff9-ba55-4350-a7b9-9314e99cce9b"
      },
      "outputs": [],
      "source": [
        "# Convert validation scores to DataFrame\n",
        "validation_df = pd.DataFrame(validation_scores).T\n",
        "\n",
        "# Print the validation scores\n",
        "validation_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ds5230",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
